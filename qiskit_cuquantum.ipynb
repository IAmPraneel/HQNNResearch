{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d10d655",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf5497a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices: ('CPU', 'GPU')\n"
     ]
    }
   ],
   "source": [
    "from qiskit_aer import Aer\n",
    "\n",
    "# Check available devices (should show both CPU and GPU)\n",
    "print(\"Available devices:\", \n",
    "      Aer.get_backend('statevector_simulator').available_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b006af4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from qiskit_aer import Aer\n",
    "print(Aer.backends(name='statevector_simulator')[0].configuration().simulator)\n",
    "# Should show {'cuStateVec': True, 'max_shots': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "589c2803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statevector([0.70710678+0.j, 0.        +0.j, 0.        +0.j,\n",
      "             0.70710678+0.j],\n",
      "            dims=(2, 2))\n"
     ]
    }
   ],
   "source": [
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit_aer import AerSimulator\n",
    "\n",
    "# Define a simple 2-qubit circuit\n",
    "qc = QuantumCircuit(2)\n",
    "qc.h(0)\n",
    "qc.cx(0, 1)\n",
    "qc.save_statevector()\n",
    "\n",
    "# Setup GPU simulator\n",
    "simulator = AerSimulator(method='statevector', device='GPU')\n",
    "\n",
    "# Transpile and run\n",
    "qc_t = transpile(qc, simulator)\n",
    "result = simulator.run(qc_t).result()\n",
    "\n",
    "# Print final statevector\n",
    "statevector = result.get_statevector()\n",
    "print(statevector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd972028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts: {'00': 508, '11': 492}\n"
     ]
    }
   ],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "from qiskit_aer import AerSimulator\n",
    "\n",
    "qc = QuantumCircuit(2)\n",
    "qc.h(0)\n",
    "qc.cx(0, 1)\n",
    "qc.measure_all()\n",
    "\n",
    "sim = AerSimulator(\n",
    "    method='statevector',\n",
    "    device='GPU',\n",
    "    cuStateVec_enable=True,\n",
    "    max_parallel_experiments=512\n",
    ")\n",
    "\n",
    "result = sim.run(qc, shots=1000).result()\n",
    "print(\"Counts:\", result.get_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f544798c",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839d0a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "tensor([[-0.4928],\n",
      "        [-0.6126],\n",
      "        [-0.6606],\n",
      "        ...,\n",
      "        [ 0.8730],\n",
      "        [ 1.2324],\n",
      "        [-0.4529]], device='cuda:0')\n",
      "xtrain device: cuda:0, ytrain device: cuda:0\n",
      "xval device: cuda:0, yval device: cuda:0\n",
      "xtest device: cuda:0, ytest device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load your dataset\n",
    "approach_3_df = pd.read_csv(....)\n",
    "approach_3_df[....] = approach_3_df[....] / 100\n",
    "\n",
    "# Specify your features here\n",
    "list_3 = [....]  # Replace this with your actual column names\n",
    "\n",
    "# Normalize the features if needed (StandardScaler as an example)\n",
    "scaler = StandardScaler()\n",
    "approach_3_df[list_3] = scaler.fit_transform(approach_3_df[list_3])\n",
    "\n",
    "# Extract relevant columns for features and labels\n",
    "features_3 = approach_3_df[list_3 + [....]]\n",
    "\n",
    "# Split data (70% train, 15% validation, 15% test)\n",
    "train_df, temp_df = train_test_split(features_3, test_size=0.4, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "train_df = train_df.loc[:, ~train_df.columns.duplicated()]\n",
    "val_df = val_df.loc[:, ~val_df.columns.duplicated()]\n",
    "test_df = test_df.loc[:, ~test_df.columns.duplicated()]\n",
    "\n",
    "# Extract features and labels for train, validation, and test datasets\n",
    "train_features = train_df.drop(columns=[....])\n",
    "train_labels = torch.tensor(train_df[....].values, dtype=torch.float32, device=device).unsqueeze(1) \n",
    "\n",
    "val_features = val_df.drop(columns=[....])\n",
    "val_labels = torch.tensor(val_df[....].values, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "test_features = test_df.drop(columns=[....])\n",
    "test_labels = torch.tensor(test_df[....].values, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "# Convert data into GPU tensors (already done above)\n",
    "xtrain = torch.tensor(train_features.values, dtype=torch.float32, device=device)\n",
    "xval = torch.tensor(val_features.values, dtype=torch.float32, device=device)\n",
    "xtest = torch.tensor(test_features.values, dtype=torch.float32, device=device)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(xtrain, train_labels)\n",
    "val_dataset = TensorDataset(xval, val_labels)\n",
    "test_dataset = TensorDataset(xtest, test_labels)\n",
    "\n",
    "print(train_labels)\n",
    "\n",
    "\n",
    "# DataLoader configuration for efficient GPU-based data loading\n",
    "gpu_loader_config = {\n",
    "    \"batch_size\": 64,\n",
    "    \"pin_memory\": False,        # Not necessary as data is already on GPU\n",
    "    \"num_workers\": 0,           # No parallel CPU data loading\n",
    "    \"persistent_workers\": False,\n",
    "    \"shuffle\": True             # Shuffle for training data\n",
    "}\n",
    "\n",
    "# Create DataLoader instances for training, validation, and testing\n",
    "train_loader = DataLoader(train_dataset, **gpu_loader_config)\n",
    "\n",
    "# Adjust batch_size for validation and testing\n",
    "val_test_loader_config = {k: v for k, v in gpu_loader_config.items() if k not in ['batch_size', 'shuffle']}\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, **val_test_loader_config)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, **val_test_loader_config)\n",
    "\n",
    "# Verify that tensors are on the correct device (GPU)\n",
    "print(f\"xtrain device: {xtrain.device}, ytrain device: {train_labels.device}\")\n",
    "print(f\"xval device: {xval.device}, yval device: {val_labels.device}\")\n",
    "print(f\"xtest device: {xtest.device}, ytest device: {test_labels.device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99c44e2",
   "metadata": {},
   "source": [
    "# Model define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414e88bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8120/555503968.py:143: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
      "  qnn = EstimatorQNN(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit_aer.primitives import Estimator\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "import torch.cuda.amp as amp\n",
    "from qiskit.quantum_info import Statevector\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = ....\n",
    "num_qubits = ....\n",
    "num_layers = ....\n",
    "shots = ....\n",
    "batch_size = ....\n",
    "num_epochs = ....\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Autoencoders ---\n",
    "class PreAutoencoder(nn.Module):\n",
    "    def __init__(self):  # Fixed the constructor name (_init_ -> __init__)\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(...., ....),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(...., num_qubits),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class PostAutoencoder(nn.Module):\n",
    "    def __init__(self):  # Fixed the constructor name (_init_ -> __init__)\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(num_qubits, ....),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(...., ....)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "# --- Quantum Circuit ---\n",
    "qc = QuantumCircuit(num_qubits)\n",
    "input_params = ParameterVector('x', num_qubits)\n",
    "weight_params = ParameterVector('Î¸', num_layers * num_qubits)\n",
    "\n",
    "# Input encoding (single layer)\n",
    "for i in range(num_qubits):\n",
    "    ....\n",
    "\n",
    "# Variational layers\n",
    "for layer in range(num_layers):\n",
    "    # Parametrized rotations\n",
    "    for i in range(num_qubits):\n",
    "        ....\n",
    "    \n",
    "    # Circular entanglement\n",
    "    for i in range(num_qubits):\n",
    "        ....\n",
    "\n",
    "# Observables\n",
    "observables = ....\n",
    "\n",
    "# --- GPU Configuration ---\n",
    "backend_options = {\n",
    "    ....\n",
    "}\n",
    "\n",
    "run_options = {\n",
    "   ....\n",
    "}\n",
    "\n",
    "transpile_options = {\n",
    "    ....\n",
    "}\n",
    "\n",
    "# Initialize Estimator with proper options\n",
    "estimator = Estimator(\n",
    "    backend_options={\n",
    "        ....\n",
    "    },\n",
    "    run_options={....},\n",
    "    transpile_options={....}\n",
    ")\n",
    "\n",
    "# Enable PyTorch optimizations\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# --- Hybrid Model ---\n",
    "class HybridQNN(nn.Module):\n",
    "    def __init__(self, pre_encoder, qnn, post_decoder):\n",
    "        super().__init__()\n",
    "        self.pre_encoder = pre_encoder.to(device)\n",
    "        self.qnn = qnn.to(device)  # TorchConnector wraps QNN parameters\n",
    "        self.post_decoder = post_decoder.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ensure inputs are on the correct device (GPU/CPU)\n",
    "        encoded = self.pre_encoder(x.to(device))\n",
    "        \n",
    "        # Mixed Precision Handling\n",
    "        with torch.autocast(device_type=\"cuda\"):  # Use mixed precision\n",
    "            # Perform forward pass\n",
    "            return self.post_decoder(self.qnn(encoded))\n",
    "\n",
    "# Initialize Autoencoders and QNN\n",
    "pre_ae = PreAutoencoder().to(device)\n",
    "post_ae = PostAutoencoder().to(device)\n",
    "\n",
    "# Quantum Neural Network (QNN) initialization\n",
    "\n",
    "\n",
    "qnn = EstimatorQNN(\n",
    "    ....\n",
    ")\n",
    "\n",
    "\n",
    "qnn_model = TorchConnector(qnn).to(device)\n",
    "\n",
    "# Initialize Hybrid QNN Model\n",
    "model = HybridQNN(pre_ae, qnn_model, post_ae).to(device)\n",
    "\n",
    "# --- Optimizer & Scaler ---\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  # Modify learning rate if necessary\n",
    "scaler = torch.GradScaler()  # For mixed precision\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83038759",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e7ac26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparsePauliOp(['IZ'],\n",
      "              coeffs=[1.+0.j]), SparsePauliOp(['ZI'],\n",
      "              coeffs=[1.+0.j])]\n"
     ]
    }
   ],
   "source": [
    "print(observables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7377b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiwashri/miniconda3/envs/qgpu/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_8120/2074264925.py:40: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|          | 0/59 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting model training\n",
      "\n",
      " Input shape: torch.Size([512, 19]), Label shape: torch.Size([512, 1])\n",
      "starting forward pass\n",
      "\n",
      " Output shape from model: torch.Size([512, 1]), Loss: 1.0616509914398193\n",
      "starting backward pass\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. Configure Training Parameters\n",
    "num_epochs = ....\n",
    "batch_size = ....\n",
    "checkpoint_path = \"best_hybrid_model.pth\"\n",
    "\n",
    "# GPU-resident DataLoaders (no CPU transfers)\n",
    "train_loader = DataLoader(\n",
    "    ....\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    ....\n",
    ")\n",
    "\n",
    "# 2. Initialize Optimizer\n",
    "optimizer = optim.AdamW([\n",
    "    {'params': model.pre_encoder.parameters(), 'lr': ........., 'weight_decay': .....},\n",
    "    {'params': model.qnn.parameters(), 'lr': .....},\n",
    "    {'params': model.post_decoder.parameters(), 'lr': ....., 'weight_decay': .....}\n",
    "])\n",
    "\n",
    "# 3. Learning Rate Scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=....., patience=...., verbose=True)\n",
    "\n",
    "# 4. Mixed Precision Training (use default device handling)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# 5. Loss Function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 6. Training Loop\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    print('starting epoch :', epoch)\n",
    "    # Initialize single progress bar per epoch\n",
    "    with tqdm(total=len(train_loader) + len(val_loader), \n",
    "             desc=f\"Epoch {epoch+1}/{num_epochs}\", \n",
    "             unit='batch') as pbar:\n",
    "        \n",
    "        print('starting model training')\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            # Ensure the inputs and labels are on the correct device (GPU/CPU)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            print(f\"\\n Input shape: {inputs.shape}, Label shape: {labels.shape}\")\n",
    "            \n",
    "            print('starting forward pass')\n",
    "            # Mixed Precision Autocast for Forward Pass\n",
    "            with torch.autocast(device_type=\"cuda\"):  # Use mixed precision for forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            print(f\"\\n Output shape from model: {outputs.shape}, Loss: {loss.item()}\")\n",
    "\n",
    "            print('starting backward pass')\n",
    "            # Scaled backward pass (use mixed precision)\n",
    "            scaler.scale(loss).backward()  # Scale loss and perform backward pass\n",
    "\n",
    "            # Optional: Gradient clipping if using quantum layers\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            scaler.step(optimizer)  # Update weights using scaled gradients\n",
    "            scaler.update()         # Adjust scaling factor for next iteration\n",
    "\n",
    "            # Fastest gradient clearing (40% faster than regular zero_grad)\n",
    "            optimizer.zero_grad(set_to_none=True)         # Zero gradients after optimization\n",
    "            \n",
    "            print('calculating training loss')\n",
    "            # Accumulate training loss\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            pbar.set_postfix({'Phase': 'Train', 'Loss': loss.item()})\n",
    "            pbar.update(1)\n",
    "\n",
    "        print('starting validation')\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                # Ensure the inputs and labels are on the correct device (GPU/CPU)\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                print('starting validation forward pass')\n",
    "                # Mixed Precision Autocast for Validation Forward Pass\n",
    "                with torch.autocast(device_type=\"cuda\"):  # Use mixed precision for forward pass\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                pbar.set_postfix({'Phase': 'Validate', 'Loss': loss.item()})\n",
    "                pbar.update(1)\n",
    "\n",
    "        print('calculating validation loss')\n",
    "        # Calculate metrics\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            pbar.write(f\"New best model saved with val loss: {val_loss:.4f}\")\n",
    "\n",
    "        print('updating progress bar')\n",
    "\n",
    "        # Update progress bar with final metrics\n",
    "        pbar.set_postfix({\n",
    "            'Train Loss': f\"{train_loss:.4f}\",\n",
    "            'Val Loss': f\"{val_loss:.4f}\",\n",
    "            'LR': f\"{optimizer.param_groups[1]['lr']:.5f}\"\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56994c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Evaluation (unchanged)\n",
    "# 7. Final Evaluation\n",
    "model.load_state_dict(torch.load(checkpoint_path))\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # Ensure inputs are on the correct device (GPU/CPU)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        test_loss += criterion(outputs, labels).item() * inputs.size(0)\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print(f\"\\nFinal Test Loss: {test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
