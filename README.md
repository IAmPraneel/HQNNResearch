# Hybrid Quantum Neural Network (HQNN)

A hybrid classicalâ€“quantum neural network (HQNN) designed to explore quantum advantages in machine learning for regression tasks on structured datasets.

> ğŸš§ This project is a work in progress. Contributions, feedback, and collaboration inquiries are welcome.

---

## âœ¨ Overview

This project combines classical neural networks with quantum circuits using Qiskit and PyTorch to build a hybrid model for predictive tasks. The goal is to evaluate whether quantum-enhanced layers can contribute to learning efficiency or expressivity in practical settings.

---

## ğŸ§  Approach

- **Pre-Autoencoder**: Reduces input dimensionality using classical neural layers.
- **Quantum Circuit**: Parametrized unitary operations and entanglement for core processing.
- **Post-Autoencoder**: Classical decoding layer for final regression output.
- **Full Pipeline**: Fully differentiable, GPU-accelerated, and designed for mixed precision.

---

## ğŸ›  Tech Stack

| **Component**             | **Technology / Library**                                |
|---------------------------|----------------------------------------------------------|
| **Deep Learning**         | PyTorch (`TorchConnector` from Qiskit ML)               |
| **Quantum Integration**   | Qiskit, Qiskit Machine Learning, Qiskit Aer, cuQuantum   |
| **Quantum Backend**       | AerSimulator with GPU support (`cuStateVec`)            |
| **Automatic Differentiation** | PyTorch Autograd with Qiskit EstimatorQNN        |
| **Mixed Precision**       | `torch.cuda.amp` (Autocast & GradScaler)                |
| **Optimization**          | AdamW, ReduceLROnPlateau                                 |
| **Data Handling**         | pandas, NumPy, StandardScaler                            |
| **Progress Tracking**     | tqdm                                                     |
| **GPU Acceleration**      | NVIDIA CUDA (`torch.device("cuda")`)                    |
| **Model Checkpointing**   | `torch.save`, `torch.load`                              |
| **Evaluation & Splits**   | scikit-learn (`train_test_split`)                       |


---

## ğŸ”§ Current Status

- âœ… Model definition (autoencoders + quantum circuit + integration)
- âœ… Qiskit backend configuration for GPU-accelerated simulation
- âœ… Mixed precision training using `torch.cuda.amp`
- âœ… Dataset preprocessing and scaling
- ğŸš§ Performance benchmarking against classical baselines
- ğŸš§ Preparing transition to PennyLane for framework comparison

---

## ğŸ’¬ Collaboration

Iâ€™m open to collaboration with:

- **Quantum ML researchers** interested in hybrid systems
- **Optimization experts** with experience in GPU acceleration or circuit transpilation
- **Labs or academic mentors** working on interpretable quantum ML
- **Open-source contributors** who want to help shape the future of quantum-classical ML

Feel free to open a GitHub Issue or connect directly if you'd like to collaborate or follow along.

---
## ğŸ“ Current Project Structure (WIP) 

```bash
HQNN/
â”œâ”€â”€ ETEPipeline             # Latest progress on the HQNN pipeline (abstracted)
â”œâ”€â”€ Autoencoder             # Jupyter notebooks for deciding architecture of classical pre and post encoders
â”œâ”€â”€ environment.yml         # Conda environment file
â”œâ”€â”€ requirements.txt        # PIP dependencies (if not using conda)
â”œâ”€â”€ README.md               # Project overview
â”œâ”€â”€ .gitignore
```
## ğŸ“ Final Project Structure (WIP) (Expected)

Empty folder are deliberately kept empty to maintain confedentiality of the research

```bash
HQNN/
â”œâ”€â”€ notebooks/               # Jupyter notebooks for experiments, EDA, prototyping
â”‚   â””â”€â”€ pipeline_experiment.ipynb
â”‚   â””â”€â”€ qiskit_pipeline_v1.ipynb
â”‚
â”œâ”€â”€ src/                    # Source code (cleaned-up Python files)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model/              # Quantum + classical model components
â”‚   â”‚   â”œâ”€â”€ autoencoders.py
â”‚   â”‚   â”œâ”€â”€ hybrid_model.py
â”‚   â”‚   â””â”€â”€ quantum_circuit.py
â”‚   â”œâ”€â”€ training/           # Training and evaluation logic
â”‚   â”‚   â”œâ”€â”€ trainer.py
â”‚   â”‚   â””â”€â”€ eval.py
â”‚   â”œâ”€â”€ utils/              # Helpers for preprocessing, logging, plotting
â”‚   â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â””â”€â”€ visualizer.py
â”‚   â””â”€â”€ config.py           # Configs, hyperparameters, paths
â”‚
â”œâ”€â”€ data/                   # Processed input data (not tracked in git)
â”‚   â””â”€â”€ raw/            
â”‚   â””â”€â”€ processed/
â”‚
â”œâ”€â”€ checkpoints/            # Model checkpoints (not tracked in git)
â”‚
â”œâ”€â”€ outputs/                # Logs, plots, evaluation results
â”‚   â””â”€â”€ predictions/
â”‚
â”œâ”€â”€ tests/                  # Unit tests for components
â”‚   â””â”€â”€ test_model.py
â”‚
â”œâ”€â”€ environment.yml         # Conda environment file
â”œâ”€â”€ requirements.txt        # PIP dependencies (if not using conda)
â”œâ”€â”€ README.md               # Project overview
â”œâ”€â”€ .gitignore
â””â”€â”€ run_pipeline.py         # Not active as project in progress


